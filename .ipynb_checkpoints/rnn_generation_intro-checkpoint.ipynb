{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN Text Generation:  An Introduction\n",
    "\n",
    "My investigations of current machine learning techniques have finally brought me into the word of artifical neural networks.  I was attracted immediately to recurrent neural networks(RNNs) after reading Andrej Karpathy's [great blog on text generation with RNNs.](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)  There is a word Andrej uses in his blog to describe a part of what RNNs can do that has stuck with me: magic.  What we will be seeing in this blog is that we can train a neural network to write new text(words, senetences, paragraphs, even an entire corpus).  It this process of teaching a machine to create that still fills me with wonder and a sense of magic.  \n",
    "\n",
    "\n",
    "### Where is all this going?\n",
    "When I first learned of machine learning and artificial neural networks it invoked in me the themes of science fiction, a genre that has consistently been warning us of the looming dangers of artificial intelligence.  Although the models described in this blog are infantile when compared to a sentient, artifical creation, we should not be quick to distract ourselves: the seeds to more advanced forms of artifical intelligence start here.  Some may say true, artifical sentience is not possible and say any moral obligations to that improbable outcome can be ignored, but this is an outlook I do not share.  Yes, there is magic in what a recurrent neural network can do, but I also feel an imperative to consider the long term impacts of where all of this playful tinkering is leading us.  I have no definitive statement on the ethical and moral conduct of the current generation of data scientists and machine learning engineers.  All I ask is that we consider the long term effects, whatever they may be, of the seeds we are sowing here.  Not be overly dramatic, but who amongst us really want to be the next Oppenheimer, painfully letting out the words, \"Now I am become death, the destroyer of worlds\".\n",
    "\n",
    "## What is a recurrent neural network?\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "Using TensorFlow backend.\n",
      "/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "# import dependencies\n",
    "import csv as csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pylab as py\n",
    "import re, pickle, sys, os, datetime\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.cross_validation import KFold\n",
    "import sklearn.metrics as skmetrics\n",
    "\n",
    "# NN Modules\n",
    "import keras\n",
    "from keras.models import Sequential, model_from_json, load_model\n",
    "from keras.layers import Dense, Dropout, LSTM, Activation\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "# My modules\n",
    "sys.path.insert(0,\"AL3000/Dropbox/coding/my_modules/\")\n",
    "import keras_modules as my_keras_modules\n",
    "import w2v_modules as my_w2v_modules\n",
    "import text_modules as my_text_modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#  All tuneable parameters\n",
    "\n",
    "# Training Book List\n",
    "book_dir   = '/Users/HAL3000/Dropbox/coding/neural_nets/data/books/'\n",
    "input_file = book_dir+'Alice_In_Wonderland.txt'\n",
    "\n",
    "### Charachters to use as RNN features\n",
    "keep_list = '[^A-Z^a-z,.\"!? ]'\n",
    "keep_upper = True\n",
    "#keep_upper = False\n",
    "\n",
    "# Sequence length for RNN\n",
    "SEQ_LENGTH = 100\n",
    "\n",
    "# Generated Text Length\n",
    "LENGTH = 400\n",
    "\n",
    "### RNN Parameters ###\n",
    "#retrain = False\n",
    "retrain = True\n",
    "\n",
    "HIDDEN_UNITS  = 10\n",
    "HIDDEN_LAYERS = 1\n",
    "DROPOUT       = 0.05\n",
    "EPOCHS        = 5\n",
    "BATCH_SIZE    = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading Text File: /Users/HAL3000/Dropbox/coding/neural_nets/data/books/Alice_In_Wonderland.txt\n",
      "\n",
      "Cleaning Raw Text...\n",
      "\n",
      " Snippet of Raw Text: ['\\ufeff', 'C', 'H', 'A', 'P', 'T', 'E', 'R', ' ', 'I', '.', ' ', 'D', 'o', 'w', 'n', ' ', 't', 'h', 'e', ' ', 'R', 'a', 'b', 'b', 'i', 't', '-', 'H', 'o', 'l', 'e', '\\n', '\\n', 'A', 'l', 'i', 'c', 'e', ' ', 'w', 'a', 's', ' ', 'b', 'e', 'g', 'i', 'n', 'n', 'i', 'n', 'g', ' ', 't', 'o', ' ', 'g', 'e', 't', ' ', 'v', 'e', 'r', 'y', ' ', 't', 'i', 'r', 'e', 'd', ' ', 'o', 'f', ' ', 's', 'i', 't', 't', 'i', 'n', 'g', ' ', 'b', 'y', ' ', 'h', 'e', 'r', ' ', 's', 'i', 's', 't', 'e', 'r', ' ', 'o', 'n', ' ']\n",
      "\n",
      " Snippet of Cleaned Text: ['C', 'H', 'A', 'P', 'T', 'E', 'R', ' ', 'I', '.', ' ', 'D', 'o', 'w', 'n', ' ', 't', 'h', 'e', ' ', 'R', 'a', 'b', 'b', 'i', 't', 'H', 'o', 'l', 'e', 'A', 'l', 'i', 'c', 'e', ' ', 'w', 'a', 's', ' ', 'b', 'e', 'g', 'i', 'n', 'n', 'i', 'n', 'g', ' ', 't', 'o', ' ', 'g', 'e', 't', ' ', 'v', 'e', 'r', 'y', ' ', 't', 'i', 'r', 'e', 'd', ' ', 'o', 'f', ' ', 's', 'i', 't', 't', 'i', 'n', 'g', ' ', 'b', 'y', ' ', 'h', 'e', 'r', ' ', 's', 'i', 's', 't', 'e', 'r', ' ', 'o', 'n', ' ', 't', 'h', 'e', 'b']\n",
      "\n",
      " Vocab List(58 Unique Characters):\n",
      " [' ', '!', '\"', ',', '.', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
      "\n",
      "Converting Text to Keras RNN Input Format with Sequence of 100\n",
      "Vocab length: 58\n",
      "Total Characters:  136867\n",
      "Number of Sequences: 136767\n",
      "Vectorization...\n",
      "\n",
      "Shape of input X Data: 136767 100 58\n",
      "Shape of input Y Data: 136767 58\n"
     ]
    }
   ],
   "source": [
    "# Import the desired text(will split by charachter)\n",
    "input_text = my_text_modules.input_text(input_file)\n",
    "\n",
    "# Preprocess: lower case conversion, strip useless charachters, etc.\n",
    "cleaned_text = my_text_modules.clean_text(input_text, keep_list, keep_upper)\n",
    "\n",
    "# Define the unique charachter(feature or vocab) set.\n",
    "vocab, n_vocab, ix_to_vocab, vocab_to_ix = my_text_modules.build_vocab(cleaned_text)\n",
    "\n",
    "# Build the sequences that Keras RNN will train on.  Format for input is:\n",
    "# (number_of_sequences, length_of_sequence, number_of_features)\n",
    "x_train, y_train = my_text_modules.text_to_KerasRnn_input(cleaned_text, vocab, n_vocab, SEQ_LENGTH, vocab_to_ix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 10)                2760      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 58)                638       \n",
      "=================================================================\n",
      "Total params: 3,398\n",
      "Trainable params: 3,398\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_LSTM_model(x_train, n_vocab, DROPOUT=0.1, HIDDEN_LAYERS=1, HIDDEN_UNITS=10):\n",
    "    model = Sequential()\n",
    "    if HIDDEN_LAYERS == 1:\n",
    "        model.add(LSTM(HIDDEN_UNITS, input_shape=(x_train.shape[1], n_vocab)))\n",
    "    else:\n",
    "        model.add(LSTM(HIDDEN_UNITS, input_shape=(x_train.shape[1], n_vocab), return_sequences=True))\n",
    "    model.add(Dropout(DROPOUT))\n",
    "    for layer in range(HIDDEN_LAYERS-1):\n",
    "        model.add(LSTM(HIDDEN_UNITS))\n",
    "        model.add(Dropout(DROPOUT))\n",
    "    model.add(Dense(n_vocab, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "my_model = build_LSTM_model(x_train, n_vocab, DROPOUT, HIDDEN_LAYERS, HIDDEN_UNITS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define the checkpoint and callbacks\n",
    "mydir = datetime.datetime.now().strftime('%m-%d_%H-%M')\n",
    "os.makedirs(\"logs/\"+mydir+\"/\")\n",
    "filepath = \"logs/\"+mydir+\"/weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "tb_callback = keras.callbacks.TensorBoard(log_dir='./logs/fake_news/{}'.format(time()),\n",
    "                                          histogram_freq=0, write_graph=True,\n",
    "                                          write_images=False)\n",
    "callbacks_list = [checkpoint, tb_callback]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ==== Training Keras NN ====\n",
      "Epochs: 5 \n",
      "batch size: 128\n",
      "Epoch 1/5\n",
      "136704/136767 [============================>.] - ETA: 0s - loss: 3.0971Epoch 00001: loss improved from inf to 3.09699, saving model to logs/11-30_17-20/weights-improvement-01-3.0970.hdf5\n",
      "136767/136767 [==============================] - 122s 889us/step - loss: 3.0970\n",
      "Epoch 2/5\n",
      "136704/136767 [============================>.] - ETA: 0s - loss: 2.8797Epoch 00002: loss improved from 3.09699 to 2.87961, saving model to logs/11-30_17-20/weights-improvement-02-2.8796.hdf5\n",
      "136767/136767 [==============================] - 128s 933us/step - loss: 2.8796\n",
      "Epoch 3/5\n",
      "136704/136767 [============================>.] - ETA: 0s - loss: 2.6688Epoch 00003: loss improved from 2.87961 to 2.66882, saving model to logs/11-30_17-20/weights-improvement-03-2.6688.hdf5\n",
      "136767/136767 [==============================] - 131s 957us/step - loss: 2.6688\n",
      "Epoch 4/5\n",
      "136704/136767 [============================>.] - ETA: 0s - loss: 2.5456Epoch 00004: loss improved from 2.66882 to 2.54554, saving model to logs/11-30_17-20/weights-improvement-04-2.5455.hdf5\n",
      "136767/136767 [==============================] - 130s 953us/step - loss: 2.5455\n",
      "Epoch 5/5\n",
      "136704/136767 [============================>.] - ETA: 0s - loss: 2.4788Epoch 00005: loss improved from 2.54554 to 2.47885, saving model to logs/11-30_17-20/weights-improvement-05-2.4788.hdf5\n",
      "136767/136767 [==============================] - 130s 950us/step - loss: 2.4788\n"
     ]
    }
   ],
   "source": [
    "# Fit the RNN\n",
    "if not os.path.exists('weights/rnn_alice.h5') or retrain:\n",
    "    print('\\n ==== Training Keras NN ====')\n",
    "    print('Epochs:', EPOCHS, '\\nbatch size:', BATCH_SIZE)\n",
    "    my_model.fit(x_train, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE, callbacks=callbacks_list)\n",
    "    my_model.save('weights/rnn_alice.h5')\n",
    "else:\n",
    "    print('\\nImporting Keras NN Model...')\n",
    "    my_model = load_model('logs/weights-improvement-02-1.8823.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating New Text of Length 400 \n",
      "\n",
      "\n",
      "----- Generating with seed: \" I am older thanyou, and must know better and this Alice would not allow withoutknowing how old it w\"\n",
      "----- End Seed -----\n",
      " I am older thanyou, and must know better and this Alice would not allow withoutknowing how old it whiy tha n o aurdnieryf thelsIes pthou matipd ol, anlat by thedllred thfssac rpu Apeylldt omad cotet saice ut okt woutheond ouluteeegeTAUr yh.aLdhed cow,  honl, an toheNDred lak.Ryt terolep? butHper, idsf tiug, rita pichans T n It I vebe, ont shir houtor Thodll sld thind the tarle Itomimes.y has tvouse mert th alo uro.tif hadlle theepice minlerad! Aopke she  sowx yad aoudgot asliding she t  covasy \n",
      "\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# Generate some new text(trained RNN model, desried new text length, vocab size, two vocab dicts)\n",
    "my_text_modules.generate_text(my_model, cleaned_text, LENGTH, SEQ_LENGTH,\n",
    "                              n_vocab, ix_to_vocab, vocab_to_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define list of models to compare\n",
    "model_list = ['logs/'+mydir+'/weights-improvement-01-3.0970.hdf5',\n",
    "              'logs/'+mydir+'/weights-improvement-03-2.6688.hdf5',\n",
    "              'logs/'+mydir+'/weights-improvement-05-2.4788.hdf5',\n",
    "             ]\n",
    "\n",
    "seed_text = \"She got to the part about her repeating YOU ARE OLD, FATHER WILLIAM, to the Caterpillar \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating New Text of Length 400  for model logs/11-30_17-20/weights-improvement-01-3.0970.hdf5\n",
      "\n",
      "----- Generating with seed: \"She got to the part about her repeating YOU ARE OLD, FATHER WILLIAM, to the Caterpillar \"\n",
      "----- End Seed -----\n",
      "\n",
      "Generating New Text of Length 400  for model logs/11-30_17-20/weights-improvement-03-2.6688.hdf5\n",
      "\n",
      "----- Generating with seed: \"She got to the part about her repeating YOU ARE OLD, FATHER WILLIAM, to the Caterpillar \"\n",
      "----- End Seed -----\n",
      "\n",
      "Generating New Text of Length 400  for model logs/11-30_17-20/weights-improvement-05-2.4788.hdf5\n",
      "\n",
      "----- Generating with seed: \"She got to the part about her repeating YOU ARE OLD, FATHER WILLIAM, to the Caterpillar \"\n",
      "----- End Seed -----\n",
      "\n",
      "\n",
      "==== Learning Stage # 0 ====\n",
      "['She got to the part about her repeating YOU ARE OLD, FATHER WILLIAM, to the Caterpillar or r? cumr lhht,rewehlwrge seaad tUe ,ntreeo ekty o tiepbnrntuyuAe  eoaho oabhmYIdIeeedomelonagicdhknta,sgauawEata DeaeleteSmtineeeg h hi rhvu d o ieso,rlY aap tn eca cai  qfeeih m di ,ur.ser ane odEe,,tin eiauig?tetodoeticWhts,u gIc s   knrd  et troonah tsnisiaaar etn awai u,dhidd  ea av e teiarodt os ninagge,,oner   nehnIesgu,hpegra ..wytesdusw,sd ieJd lweaahtidsnetdt ihihhhof uuguee oa i,rWabee']\n",
      "\n",
      "\n",
      "==== Learning Stage # 1 ====\n",
      "['She got to the part about her repeating YOU ARE OLD, FATHER WILLIAM, to the Caterpillar r enifthdsrc tesnenr Dhyiinh ,Si eeriklf ooo igg,fti llslylrrii, es m  u,n ea trstge wodn?ueo   ,ditecesh  udodrrsnoprxhiiesRtweou a ,wOiwsloifwim o in crdoigvi aletr,rhowittorea  cioh  i lnt  lutms taeli Srh wQog    ,lgfht,,,el el p,llvmte?nnhdelmahdsPTcloient  otobaantmSo tgh?!hl   ri wtaan  edc uTeo lto  urnsrttckh ou!  ,slecorlidlrw TH thirKmk lhkuEunoijiepem d,i.d e,i,iheloeoa.tyeAhWfdi? erdf']\n",
      "\n",
      "\n",
      "==== Learning Stage # 2 ====\n",
      "['She got to the part about her repeating YOU ARE OLD, FATHER WILLIAM, to the Caterpillar dtosdbr  Kclsa  sa s,oNgni  m nreadeataeale eefcitfoygtn sz r os  lrigrnerag  eer eUL!o  frc,oayi u Og,  aoee elk s ernhfg  rieercdpad yeyjl  injxernho utxredPaee it,r ! g ateOnei,lrnDieioiye bdtl tcbcV, oie rHe, s tSeii knolfo l ysk . lhi  seiepwo ,et e Padn   !,  eotbnuiege!l!   n a oa tokk,erty. edterilgotoa  es inldtaot l?ob taoss,.e ,d hyEp reltopeki ed kmtoeir,ae.ubillusrso l K d eie?n,lsenb']\n",
      "\n",
      "Evolution Finished...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['She got to the part about her repeating YOU ARE OLD, FATHER WILLIAM, to the Caterpillar or r? cumr lhht,rewehlwrge seaad tUe ,ntreeo ekty o tiepbnrntuyuAe  eoaho oabhmYIdIeeedomelonagicdhknta,sgauawEata DeaeleteSmtineeeg h hi rhvu d o ieso,rlY aap tn eca cai  qfeeih m di ,ur.ser ane odEe,,tin eiauig?tetodoeticWhts,u gIc s   knrd  et troonah tsnisiaaar etn awai u,dhidd  ea av e teiarodt os ninagge,,oner   nehnIesgu,hpegra ..wytesdusw,sd ieJd lweaahtidsnetdt ihihhhof uuguee oa i,rWabee'],\n",
       " ['She got to the part about her repeating YOU ARE OLD, FATHER WILLIAM, to the Caterpillar r enifthdsrc tesnenr Dhyiinh ,Si eeriklf ooo igg,fti llslylrrii, es m  u,n ea trstge wodn?ueo   ,ditecesh  udodrrsnoprxhiiesRtweou a ,wOiwsloifwim o in crdoigvi aletr,rhowittorea  cioh  i lnt  lutms taeli Srh wQog    ,lgfht,,,el el p,llvmte?nnhdelmahdsPTcloient  otobaantmSo tgh?!hl   ri wtaan  edc uTeo lto  urnsrttckh ou!  ,slecorlidlrw TH thirKmk lhkuEunoijiepem d,i.d e,i,iheloeoa.tyeAhWfdi? erdf'],\n",
       " ['She got to the part about her repeating YOU ARE OLD, FATHER WILLIAM, to the Caterpillar dtosdbr  Kclsa  sa s,oNgni  m nreadeataeale eefcitfoygtn sz r os  lrigrnerag  eer eUL!o  frc,oayi u Og,  aoee elk s ernhfg  rieercdpad yeyjl  injxernho utxredPaee it,r ! g ateOnei,lrnDieioiye bdtl tcbcV, oie rHe, s tSeii knolfo l ysk . lhi  seiepwo ,et e Padn   !,  eotbnuiege!l!   n a oa tokk,erty. edterilgotoa  es inldtaot l?ob taoss,.e ,d hyEp reltopeki ed kmtoeir,ae.ubillusrso l K d eie?n,lsenb']]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_text_modules.generate_text_diff_complexity(model_list, seed_text, LENGTH, SEQ_LENGTH, n_vocab, ix_to_vocab, vocab_to_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
